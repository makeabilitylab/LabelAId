{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating LabelAId with Project Sidewalk Data\n",
    "\n",
    "This notebook is evaluating the LabelAId model with the Project Sidewalk data. LabelAId is compared to other baseline models including XGBoost, Random Forest, and Logistic Regression. The evaluation metrics include accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics # Import train_test_split function\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_train = pd.read_csv('data/test_set_seattle_encoded.csv')\n",
    "\n",
    "label_counts = df_train['label_type'].value_counts()\n",
    "\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/20/50/100/200 of each label_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/labelModel_outputs_seattle_encoded.csv\")\n",
    "df_test = pd.read_csv('data/test_set_seattle_encoded.csv')\n",
    "feature_cols = ['label_CurbRamp', 'label_NoCurbRamp', 'label_NoSidewalk', 'label_Obstacle', 'label_SurfaceProblem', \n",
    "                'severity', 'zoom', 'clustered', 'distance_to_road', 'distance_to_intersection', 'tag', 'description', \n",
    "                'way_living_street', 'way_primary', 'way_residential', 'way_secondary', 'way_tertiary', 'way_trunk', 'way_unclassified']\n",
    "\n",
    "LABEL = 'verified'\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_train[df_train[LABEL]==1]\n",
    "df_minority = df_train[df_train[LABEL]==0]\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                    replace=False,    # sample without replacement\n",
    "                                    n_samples=len(df_minority),     # to match minority class\n",
    "                                    random_state=14) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# samples = [10, 20, 50, 100, 200]\n",
    "samples = [5, 10, 25, 50, 100]\n",
    "random_states = [14, 48, 69]\n",
    "results = []\n",
    "\n",
    "\n",
    "for n in samples:\n",
    "    for random_state in random_states:\n",
    "        # print(n)\n",
    "        # df_train_shuffled = df_train.sample(frac=1, random_state=random_state)\n",
    "        train_df_verified = df_test[df_test['verified'] == 1].groupby('label_type').apply(lambda x: x.sample(n=n, random_state=random_state)).reset_index(drop=True)\n",
    "        train_df_not_verified = df_test[df_test['verified'] == 0].groupby('label_type').apply(lambda x: x.sample(n=n, random_state=random_state)).reset_index(drop=True)\n",
    "\n",
    "        df_temp = pd.concat([train_df_verified, train_df_not_verified])\n",
    "        # train_df = df_train_shuffled.groupby('label_type').apply(lambda x: x.sample(n=n, random_state=1)).reset_index(drop=True)\n",
    "        train_df = pd.concat([df_temp, df_downsampled])\n",
    "\n",
    "        test_df = pd.concat([df_test, df_temp]).drop_duplicates(keep=False)\n",
    "        # test_df = df_remaining.groupby('label_type').apply(lambda x: x.sample(n=n, random_state=1)).reset_index(drop=True)\n",
    "\n",
    "        X_train = train_df[feature_cols]\n",
    "        y_train = train_df['verified']\n",
    "        # print(y_train.value_counts())\n",
    "\n",
    "        X_test = test_df[feature_cols]\n",
    "        y_test = test_df['verified']\n",
    "\n",
    "        # clf = LogisticRegression(C= 0.1, penalty=\"l1\", solver=\"liblinear\").fit(X_train, y_train)\n",
    "        # clf = MLPClassifier(hidden_layer_sizes=(24, 10), max_iter=100, alpha=1e-5, activation='relu', solver='adam', random_state=14, early_stopping=True).fit(X_train, y_train)\n",
    "        # clf = RandomForestClassifier(n_estimators= 4, max_depth=5, min_samples_leaf=4, min_samples_split=10).fit(X_train, y_train)\n",
    "        clf = xgb.XGBClassifier(n_estimators=5, max_depth=5, learning_rate=0.1, random_state=14).fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        results.append([n, random_state, accuracy, precision, recall])\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=['Samples', 'random_state', 'Accuracy', 'Precision', 'Recall'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse446",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
